2025-11-25 17:10:23,565 - INFO - 日志保存到: logs\image100_training_20251125_171023.txt
2025-11-25 17:10:25,197 - INFO - Using device: cuda
2025-11-25 17:10:25,197 - INFO - 使用数据路径: G:/0_Python/Pytorch_learning/MobileNet/data/cifar-100-python
2025-11-25 17:10:27,203 - INFO - 模型结构:
MobileNetV3(
  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act1): hard_swish()
  (bneck): Sequential(
    (0): InvertedResidualBlock(
      (conv1): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activation1): ReLU()
      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=16, bias=False)
      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activation2): ReLU()
      (se): SqueezeExcitation(
        (se): Sequential(
          (0): AdaptiveAvgPool2d(output_size=1)
          (1): Conv2d(16, 4, kernel_size=(1, 1), stride=(1, 1))
          (2): ReLU6(inplace=True)
          (3): Conv2d(4, 16, kernel_size=(1, 1), stride=(1, 1))
          (4): hard_sigmoid()
        )
      )
      (conv3): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (act3): ReLU()
      (skip): Sequential(
        (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=16, bias=False)
        (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): InvertedResidualBlock(
      (conv1): Conv2d(16, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activation1): ReLU()
      (conv2): Conv2d(72, 72, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=72, bias=False)
      (bn2): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activation2): ReLU()
      (conv3): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (act3): ReLU()
      (skip): Sequential(
        (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=16, bias=False)
        (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): Conv2d(16, 24, kernel_size=(1, 1), stride=(1, 1))
        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (2): InvertedResidualBlock(
      (conv1): Conv2d(24, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activation1): ReLU()
      (conv2): Conv2d(88, 88, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=88, bias=False)
      (bn2): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activation2): ReLU()
      (conv3): Conv2d(88, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (act3): ReLU()
    )
    (3): InvertedResidualBlock(
      (conv1): Conv2d(24, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activation1): hard_swish()
      (conv2): Conv2d(96, 96, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=96, bias=False)
      (bn2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activation2): hard_swish()
      (se): SqueezeExcitation(
        (se): Sequential(
          (0): AdaptiveAvgPool2d(output_size=1)
          (1): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1))
          (2): ReLU6(inplace=True)
          (3): Conv2d(24, 96, kernel_size=(1, 1), stride=(1, 1))
          (4): hard_sigmoid()
        )
      )
      (conv3): Conv2d(96, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (act3): hard_swish()
      (skip): Sequential(
        (0): Conv2d(24, 24, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=24, bias=False)
        (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): Conv2d(24, 40, kernel_size=(1, 1), stride=(1, 1))
        (3): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (4): InvertedResidualBlock(
      (conv1): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activation1): hard_swish()
      (conv2): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)
      (bn2): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activation2): hard_swish()
      (se): SqueezeExcitation(
        (se): Sequential(
          (0): AdaptiveAvgPool2d(output_size=1)
          (1): Conv2d(240, 60, kernel_size=(1, 1), stride=(1, 1))
          (2): ReLU6(inplace=True)
          (3): Conv2d(60, 240, kernel_size=(1, 1), stride=(1, 1))
          (4): hard_sigmoid()
        )
      )
      (conv3): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (act3): hard_swish()
    )
    (5): InvertedResidualBlock(
      (conv1): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activation1): hard_swish()
      (conv2): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)
      (bn2): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activation2): hard_swish()
      (se): SqueezeExcitation(
        (se): Sequential(
          (0): AdaptiveAvgPool2d(output_size=1)
          (1): Conv2d(240, 60, kernel_size=(1, 1), stride=(1, 1))
          (2): ReLU6(inplace=True)
          (3): Conv2d(60, 240, kernel_size=(1, 1), stride=(1, 1))
          (4): hard_sigmoid()
        )
      )
      (conv3): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (act3): hard_swish()
    )
    (6): InvertedResidualBlock(
      (conv1): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activation1): hard_swish()
      (conv2): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)
      (bn2): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activation2): hard_swish()
      (se): SqueezeExcitation(
        (se): Sequential(
          (0): AdaptiveAvgPool2d(output_size=1)
          (1): Conv2d(120, 30, kernel_size=(1, 1), stride=(1, 1))
          (2): ReLU6(inplace=True)
          (3): Conv2d(30, 120, kernel_size=(1, 1), stride=(1, 1))
          (4): hard_sigmoid()
        )
      )
      (conv3): Conv2d(120, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (act3): hard_swish()
      (skip): Sequential(
        (0): Conv2d(40, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (7): InvertedResidualBlock(
      (conv1): Conv2d(48, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activation1): hard_swish()
      (conv2): Conv2d(144, 144, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=144, bias=False)
      (bn2): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activation2): hard_swish()
      (se): SqueezeExcitation(
        (se): Sequential(
          (0): AdaptiveAvgPool2d(output_size=1)
          (1): Conv2d(144, 36, kernel_size=(1, 1), stride=(1, 1))
          (2): ReLU6(inplace=True)
          (3): Conv2d(36, 144, kernel_size=(1, 1), stride=(1, 1))
          (4): hard_sigmoid()
        )
      )
      (conv3): Conv2d(144, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (act3): hard_swish()
    )
    (8): InvertedResidualBlock(
      (conv1): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activation1): hard_swish()
      (conv2): Conv2d(288, 288, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=288, bias=False)
      (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activation2): hard_swish()
      (se): SqueezeExcitation(
        (se): Sequential(
          (0): AdaptiveAvgPool2d(output_size=1)
          (1): Conv2d(288, 72, kernel_size=(1, 1), stride=(1, 1))
          (2): ReLU6(inplace=True)
          (3): Conv2d(72, 288, kernel_size=(1, 1), stride=(1, 1))
          (4): hard_sigmoid()
        )
      )
      (conv3): Conv2d(288, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (act3): hard_swish()
      (skip): Sequential(
        (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=48, bias=False)
        (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): Conv2d(48, 96, kernel_size=(1, 1), stride=(1, 1))
        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (9): InvertedResidualBlock(
      (conv1): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activation1): hard_swish()
      (conv2): Conv2d(576, 576, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=576, bias=False)
      (bn2): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activation2): hard_swish()
      (se): SqueezeExcitation(
        (se): Sequential(
          (0): AdaptiveAvgPool2d(output_size=1)
          (1): Conv2d(576, 144, kernel_size=(1, 1), stride=(1, 1))
          (2): ReLU6(inplace=True)
          (3): Conv2d(144, 576, kernel_size=(1, 1), stride=(1, 1))
          (4): hard_sigmoid()
        )
      )
      (conv3): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (act3): hard_swish()
    )
    (10): InvertedResidualBlock(
      (conv1): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activation1): hard_swish()
      (conv2): Conv2d(576, 576, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=576, bias=False)
      (bn2): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (activation2): hard_swish()
      (se): SqueezeExcitation(
        (se): Sequential(
          (0): AdaptiveAvgPool2d(output_size=1)
          (1): Conv2d(576, 144, kernel_size=(1, 1), stride=(1, 1))
          (2): ReLU6(inplace=True)
          (3): Conv2d(144, 576, kernel_size=(1, 1), stride=(1, 1))
          (4): hard_sigmoid()
        )
      )
      (conv3): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (act3): hard_swish()
    )
  )
  (conv2): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (bn2): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act2): hard_swish()
  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
  (linear3): Linear(in_features=576, out_features=1280, bias=False)
  (bn3): BatchNorm1d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (act3): hard_swish()
  (dropout): Dropout(p=0.2, inplace=False)
  (linear4): Linear(in_features=1280, out_features=100, bias=True)
)
2025-11-25 17:10:27,213 - INFO - 超参数设置:
Batch Size: 128, Epochs: 50, Learning Rate: 0.1, Warmup Epochs: 5
2025-11-25 17:10:27,214 - INFO - 开始训练...
2025-11-25 17:10:27,214 - INFO - ================================================================================
2025-11-25 17:11:34,758 - INFO - Epoch [1/50] LR: 0.020080 | Train Loss: 4.5937, Train acc: 1.4560, Top-1: 1.46%, Top-5: 6.73% | 
Test Loss: 4.5892,Test acc: 1.7200, Top-1: 1.72%, Top-5: 7.35% | 
Epoch [1/50] , Test Once Delay: 25.2945s, Avarge Delay: 25.2945s | 
2025-11-25 17:11:34,792 - INFO - ✅ New best Top-1 accuracy: 1.72% — model saved!
2025-11-25 17:12:42,228 - INFO - Epoch [2/50] LR: 0.040060 | Train Loss: 4.4888, Train acc: 2.6280, Top-1: 2.63%, Top-5: 11.11% | 
Test Loss: 4.3203,Test acc: 4.3200, Top-1: 4.32%, Top-5: 17.63% | 
Epoch [2/50] , Test Once Delay: 25.1468s, Avarge Delay: 25.2207s | 
2025-11-25 17:12:42,252 - INFO - ✅ New best Top-1 accuracy: 4.32% — model saved!
2025-11-25 17:13:50,978 - INFO - Epoch [3/50] LR: 0.060040 | Train Loss: 4.2851, Train acc: 5.0600, Top-1: 5.06%, Top-5: 19.52% | 
Test Loss: 4.1811,Test acc: 6.5400, Top-1: 6.54%, Top-5: 23.99% | 
Epoch [3/50] , Test Once Delay: 26.2156s, Avarge Delay: 25.5523s | 
2025-11-25 17:13:51,006 - INFO - ✅ New best Top-1 accuracy: 6.54% — model saved!
2025-11-25 17:15:00,873 - INFO - Epoch [4/50] LR: 0.080020 | Train Loss: 4.2166, Train acc: 6.0820, Top-1: 6.08%, Top-5: 22.17% | 
Test Loss: 4.1869,Test acc: 6.1900, Top-1: 6.19%, Top-5: 23.63% | 
Epoch [4/50] , Test Once Delay: 26.3655s, Avarge Delay: 25.7556s | 
2025-11-25 17:16:09,552 - INFO - Epoch [5/50] LR: 0.100000 | Train Loss: 4.2120, Train acc: 6.3160, Top-1: 6.32%, Top-5: 22.51% | 
Test Loss: 4.1359,Test acc: 7.7100, Top-1: 7.71%, Top-5: 26.75% | 
Epoch [5/50] , Test Once Delay: 25.5994s, Avarge Delay: 25.7244s | 
2025-11-25 17:16:09,579 - INFO - ✅ New best Top-1 accuracy: 7.71% — model saved!
2025-11-25 17:17:16,105 - INFO - Epoch [6/50] LR: 0.099878 | Train Loss: 4.2279, Train acc: 6.0520, Top-1: 6.05%, Top-5: 21.98% | 
Test Loss: 4.2891,Test acc: 5.9100, Top-1: 5.91%, Top-5: 20.50% | 
Epoch [6/50] , Test Once Delay: 25.2821s, Avarge Delay: 25.6507s | 
2025-11-25 17:18:22,269 - INFO - Epoch [7/50] LR: 0.099513 | Train Loss: 4.1219, Train acc: 7.6660, Top-1: 7.67%, Top-5: 26.43% | 
Test Loss: 4.0570,Test acc: 8.5200, Top-1: 8.52%, Top-5: 29.01% | 
Epoch [7/50] , Test Once Delay: 25.2356s, Avarge Delay: 25.5914s | 
2025-11-25 17:18:22,297 - INFO - ✅ New best Top-1 accuracy: 8.52% — model saved!
2025-11-25 17:19:28,578 - INFO - Epoch [8/50] LR: 0.098907 | Train Loss: 4.0212, Train acc: 9.2360, Top-1: 9.24%, Top-5: 30.23% | 
Test Loss: 3.9597,Test acc: 11.0900, Top-1: 11.09%, Top-5: 33.62% | 
Epoch [8/50] , Test Once Delay: 25.2715s, Avarge Delay: 25.5514s | 
2025-11-25 17:19:28,601 - INFO - ✅ New best Top-1 accuracy: 11.09% — model saved!
2025-11-25 17:20:34,837 - INFO - Epoch [9/50] LR: 0.098063 | Train Loss: 3.9656, Train acc: 10.3340, Top-1: 10.33%, Top-5: 32.35% | 
Test Loss: 3.9214,Test acc: 11.8800, Top-1: 11.88%, Top-5: 35.11% | 
Epoch [9/50] , Test Once Delay: 25.3290s, Avarge Delay: 25.5267s | 
2025-11-25 17:20:34,859 - INFO - ✅ New best Top-1 accuracy: 11.88% — model saved!
2025-11-25 17:21:40,526 - INFO - Epoch [10/50] LR: 0.096985 | Train Loss: 3.9111, Train acc: 11.0660, Top-1: 11.07%, Top-5: 34.35% | 
Test Loss: 3.8788,Test acc: 12.3100, Top-1: 12.31%, Top-5: 36.87% | 
Epoch [10/50] , Test Once Delay: 25.0392s, Avarge Delay: 25.4779s | 
2025-11-25 17:21:40,554 - INFO - ✅ New best Top-1 accuracy: 12.31% — model saved!
2025-11-25 17:22:47,636 - INFO - Epoch [11/50] LR: 0.095677 | Train Loss: 3.8631, Train acc: 12.0620, Top-1: 12.06%, Top-5: 36.36% | 
Test Loss: 3.8597,Test acc: 12.2000, Top-1: 12.20%, Top-5: 36.26% | 
Epoch [11/50] , Test Once Delay: 25.2925s, Avarge Delay: 25.4611s | 
2025-11-25 17:23:53,910 - INFO - Epoch [12/50] LR: 0.094147 | Train Loss: 3.8254, Train acc: 12.8000, Top-1: 12.80%, Top-5: 37.65% | 
Test Loss: 3.7910,Test acc: 13.9900, Top-1: 13.99%, Top-5: 38.81% | 
Epoch [12/50] , Test Once Delay: 24.9757s, Avarge Delay: 25.4206s | 
2025-11-25 17:23:53,938 - INFO - ✅ New best Top-1 accuracy: 13.99% — model saved!
2025-11-25 17:25:00,491 - INFO - Epoch [13/50] LR: 0.092402 | Train Loss: 3.7860, Train acc: 13.6380, Top-1: 13.64%, Top-5: 38.95% | 
Test Loss: 3.7468,Test acc: 13.9500, Top-1: 13.95%, Top-5: 40.05% | 
Epoch [13/50] , Test Once Delay: 25.0545s, Avarge Delay: 25.3925s | 
2025-11-25 17:26:05,982 - INFO - Epoch [14/50] LR: 0.090451 | Train Loss: 3.7477, Train acc: 14.2400, Top-1: 14.24%, Top-5: 40.51% | 
Test Loss: 3.7736,Test acc: 13.6700, Top-1: 13.67%, Top-5: 40.79% | 
Epoch [14/50] , Test Once Delay: 25.2695s, Avarge Delay: 25.3837s | 
2025-11-25 17:27:11,505 - INFO - Epoch [15/50] LR: 0.088302 | Train Loss: 3.7145, Train acc: 14.9100, Top-1: 14.91%, Top-5: 41.64% | 
Test Loss: 3.7839,Test acc: 14.0000, Top-1: 14.00%, Top-5: 39.88% | 
Epoch [15/50] , Test Once Delay: 25.0692s, Avarge Delay: 25.3627s | 
2025-11-25 17:27:11,528 - INFO - ✅ New best Top-1 accuracy: 14.00% — model saved!
2025-11-25 17:28:16,288 - INFO - Epoch [16/50] LR: 0.085967 | Train Loss: 3.6839, Train acc: 15.6600, Top-1: 15.66%, Top-5: 42.84% | 
Test Loss: 3.6863,Test acc: 16.1100, Top-1: 16.11%, Top-5: 42.20% | 
Epoch [16/50] , Test Once Delay: 25.1731s, Avarge Delay: 25.3509s | 
2025-11-25 17:28:16,316 - INFO - ✅ New best Top-1 accuracy: 16.11% — model saved!
2025-11-25 17:29:22,178 - INFO - Epoch [17/50] LR: 0.083457 | Train Loss: 3.6514, Train acc: 16.4900, Top-1: 16.49%, Top-5: 43.97% | 
Test Loss: 3.7008,Test acc: 16.0500, Top-1: 16.05%, Top-5: 43.57% | 
Epoch [17/50] , Test Once Delay: 25.2182s, Avarge Delay: 25.3431s | 
2025-11-25 17:30:27,554 - INFO - Epoch [18/50] LR: 0.080783 | Train Loss: 3.6299, Train acc: 16.8460, Top-1: 16.85%, Top-5: 44.59% | 
Test Loss: 3.6210,Test acc: 16.9600, Top-1: 16.96%, Top-5: 45.44% | 
Epoch [18/50] , Test Once Delay: 25.1269s, Avarge Delay: 25.3311s | 
2025-11-25 17:30:27,576 - INFO - ✅ New best Top-1 accuracy: 16.96% — model saved!
2025-11-25 17:31:32,906 - INFO - Epoch [19/50] LR: 0.077960 | Train Loss: 3.6045, Train acc: 17.4980, Top-1: 17.50%, Top-5: 45.58% | 
Test Loss: 3.5651,Test acc: 17.6900, Top-1: 17.69%, Top-5: 47.39% | 
Epoch [19/50] , Test Once Delay: 25.0718s, Avarge Delay: 25.3174s | 
2025-11-25 17:31:32,933 - INFO - ✅ New best Top-1 accuracy: 17.69% — model saved!
2025-11-25 17:32:39,254 - INFO - Epoch [20/50] LR: 0.075000 | Train Loss: 3.5870, Train acc: 17.9300, Top-1: 17.93%, Top-5: 46.35% | 
Test Loss: 3.5823,Test acc: 17.6000, Top-1: 17.60%, Top-5: 46.55% | 
Epoch [20/50] , Test Once Delay: 25.1862s, Avarge Delay: 25.3108s | 
2025-11-25 17:33:45,821 - INFO - Epoch [21/50] LR: 0.071919 | Train Loss: 3.5650, Train acc: 18.1020, Top-1: 18.10%, Top-5: 46.86% | 
Test Loss: 3.5758,Test acc: 17.8200, Top-1: 17.82%, Top-5: 46.63% | 
Epoch [21/50] , Test Once Delay: 25.2554s, Avarge Delay: 25.3082s | 
2025-11-25 17:33:45,845 - INFO - ✅ New best Top-1 accuracy: 17.82% — model saved!
2025-11-25 17:34:52,686 - INFO - Epoch [22/50] LR: 0.068730 | Train Loss: 3.5467, Train acc: 18.3980, Top-1: 18.40%, Top-5: 47.68% | 
Test Loss: 3.6623,Test acc: 16.6500, Top-1: 16.65%, Top-5: 43.97% | 
Epoch [22/50] , Test Once Delay: 25.5340s, Avarge Delay: 25.3185s | 
2025-11-25 17:35:59,068 - INFO - Epoch [23/50] LR: 0.065451 | Train Loss: 3.5346, Train acc: 18.8540, Top-1: 18.85%, Top-5: 47.75% | 
Test Loss: 3.5011,Test acc: 19.6400, Top-1: 19.64%, Top-5: 48.97% | 
Epoch [23/50] , Test Once Delay: 25.3010s, Avarge Delay: 25.3177s | 
2025-11-25 17:35:59,096 - INFO - ✅ New best Top-1 accuracy: 19.64% — model saved!
2025-11-25 17:37:04,812 - INFO - Epoch [24/50] LR: 0.062096 | Train Loss: 3.5132, Train acc: 19.4780, Top-1: 19.48%, Top-5: 48.72% | 
Test Loss: 3.4969,Test acc: 19.3600, Top-1: 19.36%, Top-5: 49.64% | 
Epoch [24/50] , Test Once Delay: 25.3268s, Avarge Delay: 25.3181s | 
2025-11-25 17:38:10,582 - INFO - Epoch [25/50] LR: 0.058682 | Train Loss: 3.4952, Train acc: 19.8360, Top-1: 19.84%, Top-5: 49.10% | 
Test Loss: 3.5076,Test acc: 20.3400, Top-1: 20.34%, Top-5: 49.66% | 
Epoch [25/50] , Test Once Delay: 25.3805s, Avarge Delay: 25.3206s | 
2025-11-25 17:38:10,610 - INFO - ✅ New best Top-1 accuracy: 20.34% — model saved!
2025-11-25 17:39:17,813 - INFO - Epoch [26/50] LR: 0.055226 | Train Loss: 3.4827, Train acc: 20.1060, Top-1: 20.11%, Top-5: 49.65% | 
Test Loss: 3.4350,Test acc: 21.7300, Top-1: 21.73%, Top-5: 51.25% | 
Epoch [26/50] , Test Once Delay: 25.6458s, Avarge Delay: 25.3331s | 
2025-11-25 17:39:17,837 - INFO - ✅ New best Top-1 accuracy: 21.73% — model saved!
2025-11-25 17:40:24,130 - INFO - Epoch [27/50] LR: 0.051745 | Train Loss: 3.4648, Train acc: 20.3940, Top-1: 20.39%, Top-5: 50.14% | 
Test Loss: 3.5252,Test acc: 18.8600, Top-1: 18.86%, Top-5: 48.96% | 
Epoch [27/50] , Test Once Delay: 25.2414s, Avarge Delay: 25.3297s | 
2025-11-25 17:41:29,958 - INFO - Epoch [28/50] LR: 0.048255 | Train Loss: 3.4505, Train acc: 20.9980, Top-1: 21.00%, Top-5: 50.54% | 
Test Loss: 3.4103,Test acc: 21.8100, Top-1: 21.81%, Top-5: 52.18% | 
Epoch [28/50] , Test Once Delay: 25.2874s, Avarge Delay: 25.3282s | 
2025-11-25 17:41:29,986 - INFO - ✅ New best Top-1 accuracy: 21.81% — model saved!
2025-11-25 17:42:35,985 - INFO - Epoch [29/50] LR: 0.044774 | Train Loss: 3.4365, Train acc: 21.4660, Top-1: 21.47%, Top-5: 50.79% | 
Test Loss: 3.4486,Test acc: 21.1300, Top-1: 21.13%, Top-5: 50.39% | 
Epoch [29/50] , Test Once Delay: 25.3022s, Avarge Delay: 25.3273s | 
2025-11-25 17:43:42,323 - INFO - Epoch [30/50] LR: 0.041318 | Train Loss: 3.4188, Train acc: 21.5680, Top-1: 21.57%, Top-5: 51.56% | 
Test Loss: 3.4256,Test acc: 22.0800, Top-1: 22.08%, Top-5: 51.16% | 
Epoch [30/50] , Test Once Delay: 25.1863s, Avarge Delay: 25.3226s | 
2025-11-25 17:43:42,345 - INFO - ✅ New best Top-1 accuracy: 22.08% — model saved!
2025-11-25 17:44:48,248 - INFO - Epoch [31/50] LR: 0.037904 | Train Loss: 3.4070, Train acc: 21.9080, Top-1: 21.91%, Top-5: 51.57% | 
Test Loss: 3.3450,Test acc: 23.8100, Top-1: 23.81%, Top-5: 54.20% | 
Epoch [31/50] , Test Once Delay: 25.4443s, Avarge Delay: 25.3265s | 
2025-11-25 17:44:48,276 - INFO - ✅ New best Top-1 accuracy: 23.81% — model saved!
2025-11-25 17:45:53,896 - INFO - Epoch [32/50] LR: 0.034549 | Train Loss: 3.3865, Train acc: 22.3320, Top-1: 22.33%, Top-5: 52.54% | 
Test Loss: 3.5049,Test acc: 19.8100, Top-1: 19.81%, Top-5: 48.87% | 
Epoch [32/50] , Test Once Delay: 25.2763s, Avarge Delay: 25.3249s | 
2025-11-25 17:46:59,646 - INFO - Epoch [33/50] LR: 0.031270 | Train Loss: 3.3749, Train acc: 22.4640, Top-1: 22.46%, Top-5: 52.67% | 
Test Loss: 3.3494,Test acc: 24.0000, Top-1: 24.00%, Top-5: 53.95% | 
Epoch [33/50] , Test Once Delay: 25.4396s, Avarge Delay: 25.3284s | 
2025-11-25 17:46:59,674 - INFO - ✅ New best Top-1 accuracy: 24.00% — model saved!
2025-11-25 17:48:05,296 - INFO - Epoch [34/50] LR: 0.028081 | Train Loss: 3.3553, Train acc: 23.1020, Top-1: 23.10%, Top-5: 53.28% | 
Test Loss: 3.2975,Test acc: 24.9400, Top-1: 24.94%, Top-5: 55.79% | 
Epoch [34/50] , Test Once Delay: 25.2012s, Avarge Delay: 25.3247s | 
2025-11-25 17:48:05,322 - INFO - ✅ New best Top-1 accuracy: 24.94% — model saved!
2025-11-25 17:49:10,957 - INFO - Epoch [35/50] LR: 0.025000 | Train Loss: 3.3393, Train acc: 23.5660, Top-1: 23.57%, Top-5: 53.68% | 
Test Loss: 3.3019,Test acc: 24.2900, Top-1: 24.29%, Top-5: 55.66% | 
Epoch [35/50] , Test Once Delay: 25.3361s, Avarge Delay: 25.3250s | 
2025-11-25 17:50:15,980 - INFO - Epoch [36/50] LR: 0.022040 | Train Loss: 3.3193, Train acc: 24.0860, Top-1: 24.09%, Top-5: 54.35% | 
Test Loss: 3.2859,Test acc: 24.7900, Top-1: 24.79%, Top-5: 55.48% | 
Epoch [36/50] , Test Once Delay: 25.1323s, Avarge Delay: 25.3197s | 
2025-11-25 17:51:22,255 - INFO - Epoch [37/50] LR: 0.019217 | Train Loss: 3.3048, Train acc: 24.4360, Top-1: 24.44%, Top-5: 54.90% | 
Test Loss: 3.3232,Test acc: 23.8300, Top-1: 23.83%, Top-5: 54.50% | 
Epoch [37/50] , Test Once Delay: 25.3290s, Avarge Delay: 25.3199s | 
2025-11-25 17:52:28,395 - INFO - Epoch [38/50] LR: 0.016543 | Train Loss: 3.2854, Train acc: 24.7060, Top-1: 24.71%, Top-5: 55.42% | 
Test Loss: 3.2530,Test acc: 25.8900, Top-1: 25.89%, Top-5: 56.46% | 
Epoch [38/50] , Test Once Delay: 25.3759s, Avarge Delay: 25.3214s | 
2025-11-25 17:52:28,422 - INFO - ✅ New best Top-1 accuracy: 25.89% — model saved!
2025-11-25 17:53:34,681 - INFO - Epoch [39/50] LR: 0.014033 | Train Loss: 3.2686, Train acc: 25.5440, Top-1: 25.54%, Top-5: 56.00% | 
Test Loss: 3.1920,Test acc: 26.5400, Top-1: 26.54%, Top-5: 58.79% | 
Epoch [39/50] , Test Once Delay: 25.4342s, Avarge Delay: 25.3243s | 
2025-11-25 17:53:34,703 - INFO - ✅ New best Top-1 accuracy: 26.54% — model saved!
2025-11-25 17:54:41,085 - INFO - Epoch [40/50] LR: 0.011698 | Train Loss: 3.2493, Train acc: 25.6520, Top-1: 25.65%, Top-5: 56.56% | 
Test Loss: 3.1975,Test acc: 26.8500, Top-1: 26.85%, Top-5: 58.24% | 
Epoch [40/50] , Test Once Delay: 25.5060s, Avarge Delay: 25.3288s | 
2025-11-25 17:54:41,106 - INFO - ✅ New best Top-1 accuracy: 26.85% — model saved!
2025-11-25 17:55:47,585 - INFO - Epoch [41/50] LR: 0.009549 | Train Loss: 3.2333, Train acc: 26.1620, Top-1: 26.16%, Top-5: 57.03% | 
Test Loss: 3.1648,Test acc: 28.2500, Top-1: 28.25%, Top-5: 59.34% | 
Epoch [41/50] , Test Once Delay: 25.4050s, Avarge Delay: 25.3307s | 
2025-11-25 17:55:47,613 - INFO - ✅ New best Top-1 accuracy: 28.25% — model saved!
2025-11-25 17:56:53,740 - INFO - Epoch [42/50] LR: 0.007598 | Train Loss: 3.2146, Train acc: 26.4300, Top-1: 26.43%, Top-5: 57.59% | 
Test Loss: 3.1288,Test acc: 28.4600, Top-1: 28.46%, Top-5: 60.46% | 
Epoch [42/50] , Test Once Delay: 25.3424s, Avarge Delay: 25.3310s | 
2025-11-25 17:56:53,770 - INFO - ✅ New best Top-1 accuracy: 28.46% — model saved!
2025-11-25 17:57:58,961 - INFO - Epoch [43/50] LR: 0.005853 | Train Loss: 3.1976, Train acc: 27.2500, Top-1: 27.25%, Top-5: 57.88% | 
Test Loss: 3.1357,Test acc: 29.0200, Top-1: 29.02%, Top-5: 59.84% | 
Epoch [43/50] , Test Once Delay: 25.2925s, Avarge Delay: 25.3301s | 
2025-11-25 17:57:58,983 - INFO - ✅ New best Top-1 accuracy: 29.02% — model saved!
2025-11-25 17:59:04,625 - INFO - Epoch [44/50] LR: 0.004323 | Train Loss: 3.1777, Train acc: 27.5920, Top-1: 27.59%, Top-5: 58.79% | 
Test Loss: 3.0885,Test acc: 30.4200, Top-1: 30.42%, Top-5: 61.66% | 
Epoch [44/50] , Test Once Delay: 25.3396s, Avarge Delay: 25.3303s | 
2025-11-25 17:59:04,650 - INFO - ✅ New best Top-1 accuracy: 30.42% — model saved!
2025-11-25 18:00:10,798 - INFO - Epoch [45/50] LR: 0.003015 | Train Loss: 3.1539, Train acc: 28.1860, Top-1: 28.19%, Top-5: 59.30% | 
Test Loss: 3.0735,Test acc: 31.0400, Top-1: 31.04%, Top-5: 62.00% | 
Epoch [45/50] , Test Once Delay: 25.3076s, Avarge Delay: 25.3298s | 
2025-11-25 18:00:10,826 - INFO - ✅ New best Top-1 accuracy: 31.04% — model saved!
2025-11-25 18:01:16,077 - INFO - Epoch [46/50] LR: 0.001937 | Train Loss: 3.1439, Train acc: 28.3800, Top-1: 28.38%, Top-5: 59.37% | 
Test Loss: 3.0623,Test acc: 31.1400, Top-1: 31.14%, Top-5: 62.19% | 
Epoch [46/50] , Test Once Delay: 25.4028s, Avarge Delay: 25.3314s | 
2025-11-25 18:01:16,100 - INFO - ✅ New best Top-1 accuracy: 31.14% — model saved!
2025-11-25 18:02:22,341 - INFO - Epoch [47/50] LR: 0.001093 | Train Loss: 3.1322, Train acc: 28.5300, Top-1: 28.53%, Top-5: 59.88% | 
Test Loss: 3.0483,Test acc: 31.1600, Top-1: 31.16%, Top-5: 62.58% | 
Epoch [47/50] , Test Once Delay: 25.3725s, Avarge Delay: 25.3322s | 
2025-11-25 18:02:22,363 - INFO - ✅ New best Top-1 accuracy: 31.16% — model saved!
2025-11-25 18:03:27,917 - INFO - Epoch [48/50] LR: 0.000487 | Train Loss: 3.1219, Train acc: 29.0540, Top-1: 29.05%, Top-5: 60.41% | 
Test Loss: 3.0384,Test acc: 31.7600, Top-1: 31.76%, Top-5: 62.94% | 
Epoch [48/50] , Test Once Delay: 25.1089s, Avarge Delay: 25.3276s | 
2025-11-25 18:03:27,941 - INFO - ✅ New best Top-1 accuracy: 31.76% — model saved!
2025-11-25 18:04:33,178 - INFO - Epoch [49/50] LR: 0.000122 | Train Loss: 3.1132, Train acc: 29.1100, Top-1: 29.11%, Top-5: 60.65% | 
Test Loss: 3.0342,Test acc: 31.7400, Top-1: 31.74%, Top-5: 62.81% | 
Epoch [49/50] , Test Once Delay: 25.1354s, Avarge Delay: 25.3237s | 
2025-11-25 18:05:38,286 - INFO - Epoch [50/50] LR: 0.000000 | Train Loss: 3.1089, Train acc: 29.2340, Top-1: 29.23%, Top-5: 60.54% | 
Test Loss: 3.0355,Test acc: 32.0100, Top-1: 32.01%, Top-5: 62.87% | 
Epoch [50/50] , Test Once Delay: 25.2911s, Avarge Delay: 25.3230s | 
2025-11-25 18:05:38,310 - INFO - ✅ New best Top-1 accuracy: 32.01% — model saved!
