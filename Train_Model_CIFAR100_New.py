import logging
from datetime import datetime
from pathlib import Path
from typing import Tuple

import matplotlib.pyplot as plt
import torch
import torch.nn as nn
import time
from torch.utils.data import DataLoader
# torch.cuda.amp.GradScaler(args)å·²ç»å¼ƒç”¨, éœ€æ›´æ¢ä¸ºtorch.amp.GradScaler('cuda', args)
import torch.amp
from torch.amp import GradScaler  # å¯¼å…¥ AMP å·¥å…·

from configs.train_config import TrainingConfig, get_config, MODEL_REGISTRY, DATASET_REGISTRY

# ----------------------------
# 0. é…ç½®æ—¥å¿—
# ----------------------------
def setup_logger(log_dir="logs"):
    """è®¾ç½®æ—¥å¿—è®°å½•å™¨"""
    Path(log_dir).mkdir(parents=True, exist_ok=True)
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    log_file = Path(log_dir) / f"image100_training_{timestamp}.txt"
    
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(levelname)s - %(message)s',
        handlers=[
            logging.FileHandler(log_file, encoding='utf-8'),
            logging.StreamHandler()
        ]
    )
    logger = logging.getLogger(__name__)
    logger.info(f"æ—¥å¿—ä¿å­˜åˆ°: {log_file}")
    return logger

# ----------------------------
# 2. Training & Evaluation
# ----------------------------
def compute_topk(outputs, targets, topk=(1, 5)):
    # æ ¹æ®compute_topkçš„è¾“å…¥å†³å®šæ˜¯ç®—top-1accè¿˜æ˜¯top-5acc
    max_k = min(max(topk), outputs.size(1))
    _, pred = outputs.topk(max_k, dim=1, largest=True, sorted=True)
    pred = pred.t()
    correct = pred.eq(targets.view(1, -1).expand_as(pred))
    res = []
    for k in topk:
        k = min(k, outputs.size(1))
        correct_k = correct[:k].reshape(-1).float().sum(0)
        res.append(correct_k.item())
    return res


def train_epoch(model, loader, criterion, optimizer, device, scaler): # æ–°å¢ scaler å‚æ•°
    model.train()
    total_loss = 0
    correct = 0
    top1_correct = 0
    top5_correct = 0
    total = 0
    for inputs, targets in loader:
        inputs, targets = inputs.to(device), targets.to(device)
        optimizer.zero_grad()
        
        scaler = GradScaler()
        
        with torch.amp.autocast(device_type='cuda'):
            outputs = model(inputs)
            loss = criterion(outputs, targets)
        
        # ä½¿ç”¨ scaler è¿›è¡Œåå‘ä¼ æ’­å’Œä¼˜åŒ–
        scaler.scale(loss).backward()
        scaler.step(optimizer)
        scaler.update()

        total_loss += loss.item()
        _, predicted = outputs.max(1)
        total += targets.size(0)
        correct += predicted.eq(targets).sum().item()
        top1, top5 = compute_topk(outputs, targets, topk=(1, 5))
        top1_correct += top1
        top5_correct += top5
    return (
        total_loss / len(loader),
        100. * correct / total,
        100. * top1_correct / total,
        100. * top5_correct / total
    )


def evaluate(model, loader, criterion, device):
    model.eval()
    total_loss = 0
    correct = 0
    top1_correct = 0
    top5_correct = 0
    total = 0
    # start_time = time.time()
    with torch.no_grad():
        for inputs, targets in loader:
            inputs, targets = inputs.to(device), targets.to(device)
            outputs = model(inputs)
            loss = criterion(outputs, targets)
            total_loss += loss.item()
            _, predicted = outputs.max(1)
            total += targets.size(0)
            correct += predicted.eq(targets).sum().item()
            top1, top5 = compute_topk(outputs, targets, topk=(1, 5))
            top1_correct += top1
            top5_correct += top5
    # end_time = time.time()
    # once_delay_time = end_time - start_time
    return (
        total_loss / len(loader),
        100. * correct / total,
        100. * top1_correct / total,
        100. * top5_correct / total, 
        # once_delay_time
    )

# ----------------------------
# Builder helpers
# ----------------------------
def build_dataloaders(cfg: TrainingConfig) -> Tuple[DataLoader, DataLoader]:
    if cfg.dataset.name not in DATASET_REGISTRY:
        available = ", ".join(DATASET_REGISTRY)
        raise ValueError(f"Dataset '{cfg.dataset.name}' is not supported. Available: {available}")
    builder = DATASET_REGISTRY[cfg.dataset.name]
    return builder(
        batch_size=cfg.dataset.batch_size,
        data_path=cfg.dataset.data_path,
        num_workers=cfg.dataset.num_workers,
        pin_memory=cfg.dataset.pin_memory,
        image_size=cfg.dataset.image_size,
    )


def build_model(cfg: TrainingConfig) -> nn.Module:
    if cfg.model_name not in MODEL_REGISTRY:
        available = ", ".join(MODEL_REGISTRY)
        raise ValueError(f"Model '{cfg.model_name}' is not supported. Available: {available}")
    factory = MODEL_REGISTRY[cfg.model_name]
    return factory()
    # return factory(image_size=cfg.dataset.image_size, **cfg.model_kwargs)


# ----------------------------
# 3. Main Training Loop
# ----------------------------
def main():
    cfg = get_config()
    logger = setup_logger(log_dir = cfg.log_dir)
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    logger.info(f"Using device: {device}")
    logger.info(f"Loaded config: {cfg.experiment_name}")

    # ============================================================= #
    # Hyperparameters
    batch_size = cfg.dataset.batch_size
    epochs = cfg.epochs
    lr = cfg.optimizer.lr
    warmup_epochs = min(cfg.scheduler.warmup_epochs, max(0, epochs - 1))
    # ============================================================= #

    # åˆ›å»ºä¿å­˜ç›®å½•ï¼ˆç”±é…ç½®æä¾›ï¼‰
    save_dir = cfg.weights_dir()
    save_dir.mkdir(parents=True, exist_ok=True)

    # æ ¹æ®å®éªŒåç”Ÿæˆæƒé‡æ–‡ä»¶å
    timestamp = datetime.now().strftime("%m_%d_%H%M%S")
    save_path = save_dir / f"{cfg.experiment_name}_{timestamp}.pth"
    
    # å®šä¹‰æ–­ç‚¹æ£€æŸ¥ç‚¹è·¯å¾„ (å›ºå®šåç§°ä»¥ä¾¿æŸ¥æ‰¾)
    checkpoint_path = save_dir / f"{cfg.experiment_name}_checkpoint.pth"

    # Data
    # è®°å½•æ•°æ®è·¯å¾„
    logger.info(f"ä½¿ç”¨æ•°æ®è·¯å¾„: {cfg.dataset.data_path}")
    trainloader, testloader = build_dataloaders(cfg)

    model = build_model(cfg).to(device)
    
    logger.info(f"æ¨¡å‹ç»“æ„:\n{model}")
    logger.info(f"è¶…å‚æ•°è®¾ç½®:\nBatch Size: {batch_size}, Epochs: {epochs}, Learning Rate: {lr}, Warmup Epochs: {warmup_epochs}")

    # Loss & Optimizer 
    criterion = nn.CrossEntropyLoss(label_smoothing=cfg.label_smoothing)
    
    # å®šä¹‰ä¼˜åŒ–å™¨ 
    # optimizer = torch.optim.AdamW(
    #         model.parameters(),
    #         lr=lr,
    #         weight_decay=cfg.optimizer.weight_decay
    #     )
    # optimizer = torch.optim.SGD(
    #         model.parameters(), 
    #         lr=lr, 
    #         momentum=cfg.optimizer.momentum, 
    #         weight_decay=cfg.optimizer.weight_decay,
    #         nesterov=cfg.optimizer.nesterov
    #     )
    #------------------------------------------------------------
    #é»˜è®¤æ˜¯SGD
    if cfg.optimizer.name == "adamw":
        optimizer = torch.optim.AdamW(
            model.parameters(),
            lr=lr,
            weight_decay=cfg.optimizer.weight_decay
        )
    else:
        optimizer = torch.optim.SGD(
            model.parameters(), 
            lr=lr, 
            momentum=cfg.optimizer.momentum, 
            weight_decay=cfg.optimizer.weight_decay,
            nesterov=cfg.optimizer.nesterov
        )

    # åˆå§‹åŒ– GradScaler
    scaler = GradScaler(device="cuda")

    # warmupå­¦ä¹ ç‡è°ƒåº¦å™¨
    scheduler = torch.optim.lr_scheduler.SequentialLR(
            optimizer,
            schedulers=[
                torch.optim.lr_scheduler.LinearLR(
                    optimizer,
                    start_factor=cfg.scheduler.start_factor,
                    total_iters=warmup_epochs
                ),
                torch.optim.lr_scheduler.CosineAnnealingLR(
                    optimizer,
                    T_max=max(1, epochs - warmup_epochs)
                )
            ],
            milestones=[warmup_epochs]
        )
    
    # ----------------------------
    # æ–­ç‚¹ç»­è®­é€»è¾‘
    # ----------------------------
    start_epoch = 0
    best_top1k = 0.0
    train_acc_list = []
    test_acc_list = []
    
    if checkpoint_path.exists():
        logger.info(f"ğŸ”„ å‘ç°æ–­ç‚¹æ£€æŸ¥ç‚¹: {checkpoint_path}ï¼Œæ­£åœ¨æ¢å¤è®­ç»ƒ...")
        try:
            checkpoint = torch.load(checkpoint_path, map_location=device)
            model.load_state_dict(checkpoint['model_state_dict'])
            optimizer.load_state_dict(checkpoint['optimizer_state_dict'])
            scheduler.load_state_dict(checkpoint['scheduler_state_dict'])
            scaler.load_state_dict(checkpoint['scaler_state_dict'])
            start_epoch = checkpoint['epoch'] + 1
            best_top1k = checkpoint['best_top1k']
            train_acc_list = checkpoint.get('train_acc_list', [])
            test_acc_list = checkpoint.get('test_acc_list', [])
            logger.info(f"âœ… æˆåŠŸæ¢å¤è‡³ Epoch {start_epoch}ï¼Œå½“å‰æœ€ä½³ Top-1: {best_top1k:.2f}%")
        except Exception as e:
            logger.error(f"âŒ åŠ è½½æ£€æŸ¥ç‚¹å¤±è´¥: {e}ï¼Œå°†é‡æ–°å¼€å§‹è®­ç»ƒ")
            start_epoch = 0
    else:
        logger.info("ğŸš€ å¼€å§‹æ–°çš„è®­ç»ƒ...")
    
    logger.info("=" * 80)
    
    # Training
    total_train_time = 0.0

    # å¼€å¯äº¤äº’æ¨¡å¼
    plt.ion()
    fig, ax = plt.subplots()
    ax.set_xlabel("epoch")
    ax.set_ylabel("accuracy")
    
    for epoch in range(start_epoch, epochs):
        epoch_start = time.time()

        train_start = time.time()
        # ä¼ å…¥ scaler
        train_loss, train_acc, train_top1, train_top5 = train_epoch(model, trainloader, criterion, optimizer, device, scaler)
        train_duration = time.time() - train_start

        eval_start = time.time()
        test_loss, test_acc, test_top1, test_top5 = evaluate(model, testloader, criterion, device)
        eval_duration = time.time() - eval_start

        scheduler.step()
        epoch_duration = time.time() - epoch_start
        total_train_time += epoch_duration

        current_lr = optimizer.param_groups[0]['lr']
        train_acc_list.append(train_acc)
        test_acc_list.append(test_acc)

        logger.info(
            f"\nEpoch [{epoch + 1}/{epochs}] | LR: {current_lr:.6f}\n"
            f"----------------------------------------------------------------\n"
            f"| Metric | {'Train':<10} | {'Test':<10} |\n"
            f"|--------|------------|------------|\n"
            f"| Loss   | {train_loss:<10.4f} | {test_loss:<10.4f} |\n"
            f"| Acc    | {train_acc:<10.2f}% | {test_acc:<10.2f}% |\n"
            f"| Top-1  | {train_top1:<10.2f}% | {test_top1:<10.2f}% |\n"
            f"| Top-5  | {train_top5:<10.2f}% | {test_top5:<10.2f}% |\n"
            f"----------------------------------------------------------------\n"
            f"Time: Train {train_duration:.1f}s | Eval {eval_duration:.1f}s | Total {epoch_duration:.1f}s | Accum {total_train_time/60:.1f}m"
        )

        if test_top1 > best_top1k:
            best_top1k = test_top1
            torch.save(model.state_dict(), save_path)
            logger.info(f"âœ… New best Top-1 accuracy: {best_top1k:.2f}% â€” model saved!")

        # ä¿å­˜æ–­ç‚¹ (æ¯ä¸ª epoch ä¿å­˜ä¸€æ¬¡ï¼Œç¡®ä¿æ•°æ®å®‰å…¨ï¼Œåº”å¯¹æ¯3-4ä¸ªepochçš„ä¸­æ–­)
        checkpoint = {
            'epoch': epoch,
            'model_state_dict': model.state_dict(),
            'optimizer_state_dict': optimizer.state_dict(),
            'scheduler_state_dict': scheduler.state_dict(),
            'scaler_state_dict': scaler.state_dict(),
            'best_top1k': best_top1k,
            'train_acc_list': train_acc_list,
            'test_acc_list': test_acc_list,
        }
        torch.save(checkpoint, checkpoint_path)
        logger.info(f"ğŸ”– æ–­ç‚¹ä¿å­˜æˆåŠŸ: {checkpoint_path}")

        # å®æ—¶æ›´æ–°ç»˜å›¾
        ax.clear()
        ax.set_xlabel("epoch")
        ax.set_ylabel("accuracy")
        ax.plot(train_acc_list, label="Train Acc")
        ax.plot(test_acc_list, label="Test Acc")
        ax.legend()
        plt.pause(0.1)

    # å…³é—­äº¤äº’æ¨¡å¼å¹¶æ˜¾ç¤ºæœ€ç»ˆç»“æœ
    plt.ioff()
    plt.show()

    logger.info("=" * 80)
    logger.info(f"ğŸ‰ Training finished. Best test Top-1 accuracy: {best_top1k:.2f}%")

if __name__ == "__main__":
    main()
